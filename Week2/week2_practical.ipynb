{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47a12340",
   "metadata": {},
   "source": [
    "# Practical session 2: Regression and Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c37e15",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "## Table of Contents <a class=\"anchor\" id=\"top\"></a>\n",
    "* [1. Using regression and classification models](#section_1)\n",
    "    * [1.1 Linear regression](#section_1_1)\n",
    "    * [1.2 K-nearest neighbors regression](#section_1_2)\n",
    "    * [1.3 Logistic regression](#section_1_3)\n",
    "* [2. Implementing resampling methods](#section_2)\n",
    "    * [2.1 Linear regression](#section_2_1)\n",
    "    * [2.2. KNN regression](#section_2_2)\n",
    "    * [2.3. Logistic regression](#section_2_3)\n",
    "    * [2.4. Bootstrapping (Optional)](#section_2_4)\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845bb65b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <p>Green blocks indicate sections where you have to implement code, usually by replacing the ellipses [...].</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab751e21",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    Yellow blocks are optional questions and/or exercises.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e68e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed7616f",
   "metadata": {},
   "source": [
    "By now, we have seen two regression methods for predicting continuous output (linear regression and K-nearest neighbors), and one classification method for predicting discrete output (logistic regression). In addition, we have learned about model assessment through different resampling methods, i.e., train-test validation, (leave-one-out) cross-validation, and bootstrapping.\n",
    "\n",
    "In this practical session, we will implement these predictive models and resampling methods using the **scikit-learn** library (written as `sklearn` when you import it), which we have already installed when creating the conda environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c7bcf3",
   "metadata": {},
   "source": [
    "<h2 style=\"display: inline\"> 1. Using regression and classification models </h2> <span style=\"float: right\"><a href=\"#top\">[back to top]</a></span> <a class=\"anchor\" id=\"section_1\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2409ca",
   "metadata": {},
   "source": [
    "Scikit-learn is a collection of tools for predictive data anlysis. Among others, it has a collection of [supervised learning models](https://scikit-learn.org/stable/supervised_learning.html), with extensive [documentation](https://scikit-learn.org/stable/modules/classes.html) on each model which also contains example code. The models we are using in this practical are\n",
    "* [1.1.1 Ordinary Least Squares](https://scikit-learn.org/stable/modules/linear_model.html#ordinary-least-squares) ([API](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression)), \n",
    "* [1.6.3 Nearest Neighbors Regression](https://scikit-learn.org/stable/modules/neighbors.html#nearest-neighbors-regression) ([API](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html#sklearn.neighbors.KNeighborsRegressor)), and\n",
    "* [1.1.11 Logistic regression](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression) ([API](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression)).\n",
    "\n",
    "\n",
    "\n",
    "For now, we will follow these steps when building a regression/classification model:\n",
    "1. Load the dataset.\n",
    "2. Declare the model we will use.\n",
    "3. Fit the training data to the model.\n",
    "4. Use the model to predict unseen data.\n",
    "\n",
    "Fortunately, scikit-learn already has a few built-in [datasets](https://scikit-learn.org/stable/datasets.html). In this practical we will only be using the smaller datasets, or [toy datasets](https://scikit-learn.org/stable/datasets/toy_dataset.html), namely the diabetes dataset for regression, and iris dataset for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed6661d",
   "metadata": {},
   "source": [
    "<h3 style=\"display: inline\"> 1.1 Linear regression </h3> <span style=\"float: right\"><a href=\"#top\">[back to top]</a></span> <a class=\"anchor\" id=\"section_1_1\"></a> \n",
    "\n",
    "In this section, we demonstrate how to apply linear regression on the diabetes dataset. This dataset contains 442 instances and 10 features, e.g., age, sex, and bmi, to predict a quantitative measure of diabetes progression one year after baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c56fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the dataset\n",
    "from sklearn import datasets\n",
    "diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y = True, as_frame = True, scaled = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7d36d1",
   "metadata": {},
   "source": [
    "You can check what the arguments of the `load_diabetes` function does [here](\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html#sklearn.datasets.load_diabetes). Essentially,\n",
    "* `return_X_y = True` tells the function to return a separate object for the predictors (X) and the response variable (y),\n",
    "* `as_frame = True` tells the function to return a `pandas.DataFrame` object, and\n",
    "* `scaled = False` returns unscaled values of the data.\n",
    "\n",
    "[`pandas`](https://pandas.pydata.org/docs/user_guide/index.html) is a library that helps you work with datasets by \n",
    "providing functions for analyzing, cleaning, exploring, and manipulating data. For example, with the command `head`, you can see the first few rows of your data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0fc67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictors (or features, or independent variables)\n",
    "diabetes_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d665b9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Response (or dependent variable)\n",
    "diabetes_y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e3f483",
   "metadata": {},
   "source": [
    "For the sake of visualization, let us make a model with only 1 predictor, the bmi. You can easily subset a `DataFrame` object by putting its column name(s) in square brackets. However, a single bracket will output a `pandas.Series` object (which we can't directly use to fit the model), whereas a double bracket will output a `pandas.DataFrame` object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6818b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Subsetting with single brackets\")\n",
    "print(\"Data type: {}, \\nDimension: {}\\n\".format(type(diabetes_X['bmi']), diabetes_X['bmi'].shape))\n",
    "\n",
    "print(\"Subsetting with double brackets\")\n",
    "print(\"Data type: {}, \\nDimension: {}\".format(type(diabetes_X[['bmi']]), diabetes_X[['bmi']].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8603d43",
   "metadata": {},
   "source": [
    "Now, let's build the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265792ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 2. Declare the model\n",
    "linreg_model = LinearRegression()\n",
    "\n",
    "# 3. Fit the model to the dataset\n",
    "linreg_model.fit(diabetes_X[['bmi']], diabetes_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1839e8bf",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    Fit the model on the data subsetted with single brackets. Try to fix the error by following the instructions on the error message.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a098f5c",
   "metadata": {},
   "source": [
    "Before we go on to predicting new output, let's first visualize what our model is doing. Recall that linear regression is just finding a straight line that best fits the data. This line can be drawn by getting the intercept and $\\beta_1$ cofficient from the model through the the `intercept_` and `coef_` attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b54d714",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(linreg_model.intercept_)\n",
    "print(linreg_model.coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925dd197",
   "metadata": {},
   "source": [
    "We can overlay this line over the real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aba0d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select two points: the minimum and maximum of the bmi\n",
    "x1 = diabetes_X[['bmi']].min()\n",
    "x2 = diabetes_X[['bmi']].max()\n",
    "\n",
    "# Calculate y values using slope-intercept equation\n",
    "y1 = linreg_model.coef_[0] * x1 + linreg_model.intercept_\n",
    "y2 = linreg_model.coef_[0] * x2 + linreg_model.intercept_\n",
    "\n",
    "plt.scatter(diabetes_X[['bmi']], diabetes_y)   # Plot real data\n",
    "plt.plot([x1, x2], [y1, y2], color='red')      # Plot predicted line\n",
    "plt.xlabel('BMI')\n",
    "plt.ylabel('Disease progression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168c0a8b",
   "metadata": {},
   "source": [
    "Finally, you can use the model to predict what the expected disease progression is for a given BMI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da94cc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Use the model to predict new output\n",
    "# e.g., people with BMI of 25, 35, and 28.5\n",
    "linreg_model.predict([[25], [35], [28.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a776f4",
   "metadata": {},
   "source": [
    "Note that these values lie on the red line of the figure above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950cefa1",
   "metadata": {},
   "source": [
    "<h3 style=\"display: inline\"> 1.2 K-nearest neighbors regression </h3> <span style=\"float: right\"><a href=\"#top\">[back to top]</a></span> <a class=\"anchor\" id=\"section_1_2\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c7c6e9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h3>Exercise</h3>\n",
    "        <p>Follow the same workflow as above and perform KNN regression on the diabetes dataset, using only the BMI as the feature.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db95f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Dataset already loaded (diabetes_X[['bmi']] and diabetes_y)\n",
    "\n",
    "# Import k-nearest neighbors model from sklearn\n",
    "from sklearn.neighbors import ...\n",
    "\n",
    "# 2. Declare the model\n",
    "knn_model = ...\n",
    "\n",
    "# 3. Fit the model to the dataset\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddcadaf",
   "metadata": {},
   "source": [
    "Since KNN is not a linear model, it has no `coef_` or `intercept_` attribute, and we cannot draw a straight line to see where our predictions will lie on. We will visualize the predicted values by creating the entire range of x values and seeing what is predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e300a2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 100 evenly-spaced data points between the minimum and maximum bmi values\n",
    "x_values = np.linspace(diabetes_X[['bmi']].min(), diabetes_X[['bmi']].max(), num = 100)\n",
    "\n",
    "# 4. Predict\n",
    "y_values = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783a36ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(diabetes_X[['bmi']], diabetes_y)   # Plot real data\n",
    "plt.plot(x_values, y_values, color='red')      # Plot predicted values\n",
    "plt.xlabel('BMI')\n",
    "plt.ylabel('Disease progression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e4ce98",
   "metadata": {},
   "source": [
    "<h2 style=\"display: inline\"> 1.3 Logistic regression </h2> <span style=\"float: right\"><a href=\"#top\">[back to top]</a></span> <a class=\"anchor\" id=\"section_1_3\"></a>\n",
    "\n",
    "For this, we will use the iris dataset to perform classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6ee2bb",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h3>Exercise</h3>\n",
    "    <p>Load and <b>explore</b> the iris toy dataset, then follow the same workflow as above to perform logistic regression.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d2dd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the iris dataset\n",
    "iris_X, iris_y = ...(return_X_y = True, as_frame = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4f680c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    How many features are in this dataset? How many samples? How many classes of irises are there?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcc3caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import logistic regression model from sklearn\n",
    "from ... import ...\n",
    "\n",
    "# 2. Declare the model\n",
    "logreg_model = ...\n",
    "\n",
    "# 3. Fit the model to the dataset\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1aa57a9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    If you got a <b>ConvergenceWarning</b>, try reading the error message and see if you can fix it!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ea250f",
   "metadata": {},
   "source": [
    "Try predicting the class of the first 10 samples of the dataset, are these the same as the true classes in `iris_y`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0c610e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_iris_y = ...\n",
    "\n",
    "# Check if predicted_iris_y is the same as the iris_y\n",
    "all(predicted_iris_y == iris_y[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a215ec42",
   "metadata": {},
   "source": [
    "<h2 style=\"display: inline\">2. Implementing resampling methods</h2> <span style=\"float: right\"><a href=\"#top\">[back to top]</a></span> <a class=\"anchor\" id=\"section_2\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329f7e73",
   "metadata": {},
   "source": [
    "In the previous section, we trained our models on the entire dataset, which can lead to overfitting of the data and underestimation of the error. We will mitigate this by using different resampling methods and evaluating model performance. This adds two more steps from our approach above:\n",
    "\n",
    "<ol>\n",
    "<li> Load the dataset. </li>\n",
    "<b><li>Partition the dataset.</li></b>\n",
    "<li>Declare the model we will use.</li>\n",
    "<li>Fit the training data to the model.</li>\n",
    "<li>Use he model to predict unseen data.</li>\n",
    "<b><li>Evaluate the model.</li></b>\n",
    "</ol>\n",
    "\n",
    "These new steps go hand-in-hand and are also grouped together in [Chapter 3](https://scikit-learn.org/stable/model_selection.html) of the scikit-learn user guide, with documentation of the resampling methods found [here](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection).\n",
    "\n",
    "Once again, we will start with the linear regression model on the diabetes dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccefefc7",
   "metadata": {},
   "source": [
    "<h2 style=\"display: inline\">2.1 Linear regression</h2> <span style=\"float: right\"><a href=\"#top\">[back to top]</a></span> <a class=\"anchor\" id=\"section_2_1\"></a>\n",
    "\n",
    "#### 2.1.1 Evaluate model performance with no partitioning\n",
    "\n",
    "We will repeat the code from section 1.1 here with some changes. Mainly, we demonstrate the use of the `score` function, which is a general function for evaluating models. For linear regression, it computes the $R^2$ score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e4921f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Set scaled = True so features are more comparable\n",
    "diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y = True, as_frame = True, scaled = True)\n",
    "\n",
    "# Can also combine two steps like this\n",
    "# We will use the entire dataset this time\n",
    "linreg_model = LinearRegression().fit(diabetes_X, diabetes_y)\n",
    "\n",
    "# 6. Evaluate the model\n",
    "linreg_model.score(diabetes_X, diabetes_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c2b69b",
   "metadata": {},
   "source": [
    "#### 2.1.2 Evaluate model performance with train-test partitioning\n",
    "\n",
    "Partitioning of the dataset can be done with [`model_selection.train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split) (default: 0.75-0.25 split). The `random_state` parameter is used for reproducibility, so everyone who runs the code with the same random state has their data split the same way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab69d8d4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h3>Exercise</h3>\n",
    "    <p>Partition the data with <code>train_test_split</code> and compare model performance on training and test data. </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ec0c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ...\n",
    "db_X_train, db_X_test, db_y_train, db_y_test = ...(..., random_state = 42)\n",
    "\n",
    "# Fit data only on training model\n",
    "linreg_model = ...\n",
    "\n",
    "linreg_train_score = ...\n",
    "linreg_test_score = ...\n",
    "\n",
    "# Compare model performance on test vs train data\n",
    "print(\"Score on train data:\", linreg_train_score)\n",
    "print(\"Score on test data:\", linreg_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619bfa47",
   "metadata": {},
   "source": [
    "As expected, our model performs worse on data it has never seen before (the test data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14f29e9",
   "metadata": {},
   "source": [
    "#### 2.1.3 Cross-validation\n",
    "\n",
    "[`KFold`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) is an object class that is used to generate groups for cross-validation. It generates indices for splitting the data into `n_split` number of groups. We visualize this below (you can ignore the code inside the `for` loop):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401a69c6",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits)\n",
    "\n",
    "fig, ax = plt.subplots() # Create empty figure\n",
    "\n",
    "for fold_i, (train_index, test_index) in enumerate(kf.split(diabetes_X, diabetes_y)):\n",
    "    \n",
    "    n_samples = len(diabetes_X)\n",
    "    \n",
    "    # Create an array of zeros 1 and make the test set indices = 1\n",
    "    indices = np.zeros(n_samples)\n",
    "    indices[test_index] = 1\n",
    "\n",
    "    # Visualize the results\n",
    "    ax.scatter(range(n_samples),\n",
    "               [fold_i + 1] * n_samples,  \n",
    "               c=indices,              # Color is determined values of the array (0 or 1)\n",
    "               marker=\"_\", lw=10,\n",
    "               vmin=-0.2, vmax=1.2)\n",
    "\n",
    "# Formatting\n",
    "ax.set(xlabel=\"Sample index\", ylabel=\"CV iteration\",\n",
    "       yticks=np.arange(n_splits) + 1, ylim=[n_splits + 1, -0.2])\n",
    "\n",
    "ax.legend([\"Testing set\", \"Training set\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227f5c35",
   "metadata": {},
   "source": [
    "As you can see, the dataset gets partitioned into 5 groups, with the test set changing every fold. What is important from the code block above is that you will have to **iterate the `KFold` object you declared in a `for` loop.** You can then train and evaluate the model inside each loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bff4ac",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h3>Exercise</h3>\n",
    "    <p>Implement 5-fold cross validation by filling in the code below.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb65b4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_per_fold_train = []\n",
    "scores_per_fold_test = []\n",
    "\n",
    "n_splits = 5\n",
    "kf = ...\n",
    "\n",
    "i = 1\n",
    "for (train_index, test_index) in ...:\n",
    "    # Subset training indices\n",
    "    db_X_train_i = diabetes_X.iloc[...]\n",
    "    db_y_train_i = diabetes_y.iloc[...]\n",
    "    \n",
    "    # Subset test indices\n",
    "    db_X_test_i = diabetes_X.iloc[...]\n",
    "    db_y_test_i = diabetes_y.iloc[...]\n",
    "    \n",
    "    # Declare model and fit data only on training model of this fold\n",
    "    linreg_model = ...\n",
    "\n",
    "    # Store model performance on test vs train data\n",
    "    scores_per_fold_train.append(...)\n",
    "    scores_per_fold_test.append(...)\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "# Just code for printing, can ignore\n",
    "printing = list(zip(np.arange(1, n_splits + 1), scores_per_fold_train, scores_per_fold_test))\n",
    "print('\\n'.join('Fold {}\\n  Train: {:.2f}\\n  Test: {:.2f}'.format(*fold) for fold in printing))\n",
    "print('Average train score: {:.3f}'.format(np.mean(scores_per_fold_train)))\n",
    "print('Average test score: {:.3f}'.format(np.mean(scores_per_fold_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca762c6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    Leave-one-out cross-validation (LOOCV) is a special case of cross-validation. What would <b>n_splits</b> have to be if you want to perform LOOCV?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b92413",
   "metadata": {},
   "source": [
    "<h3 style=\"display: inline\">2.2 KNN  regression</h3> <span style=\"float: right\"><a href=\"#top\">[back to top]</a></span> <a class=\"anchor\" id=\"section_2_2\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5675e085",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h3>Exercise</h3>\n",
    "        <p>Implement KNN on the train-test partitioning and 5-fold cross-validation. In both cases, compare scores between training and test data.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5741d86e",
   "metadata": {},
   "source": [
    "#### 2.2.1 Train-test partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94de198b",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_X, diabetes_y = ...\n",
    "\n",
    "# Partition data into train and test data\n",
    "db_X_train, db_X_test, db_y_train, db_y_test = ...\n",
    "\n",
    "# Declare model and fit\n",
    "knn_model = ...\n",
    "\n",
    "# Compare scores\n",
    "knn_train_score = ...\n",
    "knn_test_score = ...\n",
    "\n",
    "print(\"Score on train data:\", knn_train_score)\n",
    "print(\"Score on test data:\", knn_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76e8de8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    1. Compared to linear regression, the difference between the train and test performance of KNN is much higher. Can you explain this? <br> 2. What is the default number of neighbors used by the model? <br>   \n",
    "    3. Try using different number of neighbors for the model and compare their performances.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73d2d83",
   "metadata": {},
   "source": [
    "#### 2.2.2 Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1851e4cc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b>Challenge:</b> Try and see if you can implement this without looking at the code from the previous section! (But looking at the documentation is allowed.)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354e7fce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores_per_fold_train = []\n",
    "scores_per_fold_test = []\n",
    "\n",
    "n_splits = 5\n",
    "kf = ...\n",
    "\n",
    "i = 1\n",
    "for ... in ...:\n",
    "    db_X_train_i = ...\n",
    "    db_y_train_i = ...\n",
    "    \n",
    "    db_X_test_i = ...\n",
    "    db_y_test_i = ...\n",
    "    \n",
    "    # Fit data only on training model of this fold\n",
    "    knn_model = ...\n",
    "\n",
    "    # Store model performance on test vs train data\n",
    "    scores_per_fold_train.append(...)\n",
    "    scores_per_fold_test.append(...)\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "print('Average train score: {:.3f}'.format(np.mean(scores_per_fold_train)))\n",
    "print('Average test score: {:.3f}'.format(np.mean(scores_per_fold_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14abdff7",
   "metadata": {},
   "source": [
    "<h3 style=\"display: inline\">2.3 Logistic regression</h3> <span style=\"float: right\"><a href=\"#top\">[back to top]</a></span> <a class=\"anchor\" id=\"section_2_3\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b57d8a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h3>Exercise</h3>\n",
    "        <p>Implement logistic regression on the train-test partitioning and 5-fold cross-validation of the iris dataset. In both cases, compare scores between training and test data.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0a33ae",
   "metadata": {},
   "source": [
    "#### 2.3.1 Train-test partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dd268f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the iris dataset\n",
    "...\n",
    "\n",
    "# Partition data into train and test data\n",
    "...\n",
    "\n",
    "# Declare model and fit\n",
    "logreg_model = ...\n",
    "\n",
    "# Compare scores\n",
    "logreg_train_score = ...\n",
    "logreg_test_score = ...\n",
    "\n",
    "print(\"Score on train data:\", logreg_train_score)\n",
    "print(\"Score on test data:\", logreg_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6089121b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    For regression models, the score is the $R^2$ value. What does the <b>score</b> refer to for logistic regression?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7b59bc",
   "metadata": {},
   "source": [
    "#### 2.3.2 Cross-validation\n",
    "\n",
    "For this section, it is important that you use `StratifiedKFold` instead of `KFold`. Recall the barplot we generated in 2.1.3, and notice that `KFold` splits the dataset into groups according in an orderly manner. Now notice how the `iris` dataset is organized (the different colors refer to different classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f29b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(7, 1)) # Create empty figure\n",
    "n_samples = len(iris_X)\n",
    "    \n",
    "ax.scatter(range(n_samples), [1]*n_samples, c=iris_y, marker=\"_\", lw=10, cmap = plt.cm.Paired)\n",
    "    \n",
    "# Formatting\n",
    "ax.set(xlabel=\"Sample index\")\n",
    "ax.yaxis.set_tick_params(labelleft=False)\n",
    "ax.set_yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e5cbd8",
   "metadata": {},
   "source": [
    "Unlike `Kfold`, each group created by `StratifiedKFold` will have an equal number of samples from each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cb0e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ...\n",
    "\n",
    "scores_per_fold_train = []\n",
    "scores_per_fold_test = []\n",
    "\n",
    "kf = ...\n",
    "\n",
    "i = 1\n",
    "for ... in ...:\n",
    "    \n",
    "    # Training data\n",
    "    ...\n",
    "    ...\n",
    "    \n",
    "    # Test data\n",
    "    ...\n",
    "    ...\n",
    "    \n",
    "    # Fit data only on training model of this fold\n",
    "    logreg_model = ...  \n",
    "\n",
    "    # Store model performance on test vs train data\n",
    "    scores_per_fold_train.append(...)\n",
    "    scores_per_fold_test.append(...)\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "print('Average train score: {:.3f}'.format(np.mean(scores_per_fold_train)))\n",
    "print('Average test score: {:.3f}'.format(np.mean(scores_per_fold_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c397b0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    Compare the results of using <code>KFold</code> with <code>StratifiedKFold</code>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b053d18",
   "metadata": {},
   "source": [
    "<h3 style=\"display: inline\">2.4 Bootstrapping (Optional)</h3> <span style=\"float: right\"><a href=\"#top\">[back to top]</a></span> <a class=\"anchor\" id=\"section_2_4\"></a> \n",
    "\n",
    "In this section, we demonstrate bootstrapping with linear regression on the diabetes dataset. We will implement this using the `resample` function with `replace=TRUE`, indicating that we are sampling with replacement. We will sample from the row labels (`.index`) of the dataset, which in the diabetes dataset is just a range of numbers from 0 to 441."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d708d6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_X.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f19fdb5",
   "metadata": {},
   "source": [
    "We will resampling our training data `n_iteration` times, fitting `n_iteration` linear regression models in the process. We will also store all $R^2$ values and model coefficient estimates in a `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a993c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "n_iterations = 1000\n",
    "\n",
    "# Initialize estimator\n",
    "linreg_model = LinearRegression()\n",
    "\n",
    "# Initialize DataFrame to hold bootstrap statistics\n",
    "bootstrapped_stats = pd.DataFrame()\n",
    "\n",
    "# Each loop iteration is a single bootstrap resample and model fit\n",
    "for i in range(n_iterations):\n",
    "    \n",
    "    # As training set, sample with replacement using row labels\n",
    "    # Define test set to be all observations not in training set\n",
    "    train_index = resample(diabetes_X.index, replace=True)\n",
    "    test_index = diabetes_X.index[~diabetes_X.index.isin(train_index)]\n",
    "    \n",
    "    # Can reuse same code from the cross-validation!\n",
    "    db_X_train_i = diabetes_X.iloc[train_index]\n",
    "    db_y_train_i = diabetes_y.iloc[train_index]\n",
    "    \n",
    "    db_X_test_i = diabetes_X.iloc[test_index]\n",
    "    db_y_test_i = diabetes_y.iloc[test_index]\n",
    "\n",
    "    # Fit model\n",
    "    linreg_model.fit(db_X_train_i, db_y_train_i)\n",
    "\n",
    "    # Store model coefficients and score in DataFrame\n",
    "    data = {'intercept':linreg_model.intercept_,\n",
    "            'beta_coefficient':linreg_model.coef_[0],\n",
    "            'train_score':linreg_model.score(db_X_train_i, db_y_train_i),\n",
    "            'test_score':linreg_model.score(db_X_test_i, db_y_test_i)\n",
    "    }\n",
    "\n",
    "    bootstrapped_stats_i = pd.DataFrame(data, index = [i])\n",
    "    \n",
    "    # Concatenate result\n",
    "    bootstrapped_stats = pd.concat(objs=[bootstrapped_stats,\n",
    "                                         bootstrapped_stats_i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02b84a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bootstrapped_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a2c49b",
   "metadata": {},
   "source": [
    "Let's take a look at the statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc34e12d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize = (7, 7))\n",
    "\n",
    "axs[0, 0].hist(bootstrapped_stats[\"intercept\"], bins=100)\n",
    "axs[0, 0].set_title('Intercept')\n",
    "axs[1, 0].hist(bootstrapped_stats[\"beta_coefficient\"], bins=100)\n",
    "axs[1, 0].set_title('Beta')\n",
    "axs[0, 1].hist(bootstrapped_stats[\"train_score\"], bins=100)\n",
    "axs[0, 1].set_title('Training score')\n",
    "axs[0, 1].set_xlim(0.2, 0.8)\n",
    "axs[1, 1].hist(bootstrapped_stats[\"test_score\"], bins=100)\n",
    "axs[1, 1].set_title('Test score')\n",
    "axs[1, 1].set_xlim(0.2, 0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fadfdcb",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    Implement bootstrapping for KNN and logistic regression. Do the training and test scores follow the same distribution as those of linear regression? <br> Additionally, compare the runtime of all three methods over these bootstrapping iterations. Does this match with their computational complexity?\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
