{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "For those of you who are opening this in google colab. To speed all the computations in this notebook up, you can access gpu's from Google. In the upper right corner of google colab there is a small icon that says RAM and Disk (if this is not the case, select the arrow pointing downwards and select connect to a hosted runtime) . If you click there a subtab will open that says on the bottom *change runtime type*. Click on this and select GPU's under hardware accellerator and save your changes. \n",
        "\n",
        "Doing this will delete your variables (if there are any in the current session). So you will need to rerun all cells."
      ],
      "metadata": {
        "id": "OJnMyT3xMkVW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jrOOdI7F1aS",
        "outputId": "b1095174-a711-4d0b-c1e1-d923cf315dd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.10/dist-packages (0.19.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (1.4.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (1.22.4)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (2.2.1)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (0.4.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability) (0.1.8)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (2.25.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imageio) (1.22.4)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio) (8.4.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/tensorflow/docs\n",
            "  Cloning https://github.com/tensorflow/docs to /tmp/pip-req-build-k7n8f98r\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/tensorflow/docs /tmp/pip-req-build-k7n8f98r\n",
            "  Resolved https://github.com/tensorflow/docs to commit ba879887790ded183c04540d5386df4962f48eeb\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==0.0.0.dev0) (0.8.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==0.0.0.dev0) (1.4.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==0.0.0.dev0) (3.1.2)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==0.0.0.dev0) (5.8.0)\n",
            "Requirement already satisfied: protobuf>=3.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==0.0.0.dev0) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from tensorflow-docs==0.0.0.dev0) (6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->tensorflow-docs==0.0.0.dev0) (2.1.2)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==0.0.0.dev0) (2.16.3)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==0.0.0.dev0) (4.3.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==0.0.0.dev0) (5.3.0)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow-docs==0.0.0.dev0) (5.7.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==0.0.0.dev0) (23.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==0.0.0.dev0) (0.19.3)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core->nbformat->tensorflow-docs==0.0.0.dev0) (3.3.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install tensorflow-probability\n",
        "\n",
        "# to generate gifs\n",
        "%pip install imageio\n",
        "%pip install git+https://github.com/tensorflow/docs\n",
        "\n",
        "from IPython import display\n",
        "\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "Q7MlpTy8IRs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "def select_device(prefer_gpu=True):\n",
        "    local_device_protos = device_lib.list_local_devices()\n",
        "    gpus = [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
        "    if (len(gpus) > 0) and prefer_gpu:\n",
        "        return gpus[0]\n",
        "    else:\n",
        "        return [x.name for x in local_device_protos if x.device_type == 'CPU'][0]"
      ],
      "metadata": {
        "id": "ZBJ3DffwISuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This code sets the device to use to GPU if you have one available\n",
        "device = select_device(prefer_gpu=True)\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "_Nt8FU4BIVRJ",
        "outputId": "8192e6db-70a7-4661-952c-ed8ab1c9380b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Theory recap\n",
        "As seen in the theory lecture on Representation learning, the end goal of training a variational auto-encoder is finding a model that approximates the data generating distribution $p_{data}$:\n",
        "\n",
        "$$\\theta*=\\textrm{arg}\\textrm{min}_{\\theta\\in\\mathcal{M}}d(p_{data},p_\\theta)$$\n",
        "\n",
        "with $d$ the Kullback-Leibler divergence.\n",
        "\n",
        "It can be shown that this minimization is equivalent to maximizing the log-likelihood $log{p_\\theta}$ over a discrete dataset sampled from $p_{data}$. However, computing $log{p_\\theta}$ is intractable due to the marginalization over $Z$, the latent random variable.\n",
        "\n",
        "Therefore, we approximate this problem by maximizing a (tractable) lower-bound on $log{p_\\theta}$, namely, the Evidence Lower BOund (ELBO):\n",
        "\n",
        "$$\\log p_\\theta(x) \\geq \\mathbb{E}_{z\\sim q_\\lambda(z|x)}[\\log{\\frac{p_\\theta(x|z)}{q_\\lambda(z|x)}}]$$\n",
        "\n",
        "In order to be able to sample meaningful latent representations, we impose a unit Gaussian prior on $Z$. This is often reffered to as teh reparameterization trick. Without the reparameterization trick, backpropagation would be stuck at the random bottleneck node. We cannot backpropagate through a random variable.\n",
        "\n",
        "Therefore, we introduce a normally distributed random variable $\\epsilon$ and we let the encoder output the parameters of a multivariate normal distribution as a vector. A latent representation for an input $x$ can then be constructed as follows:\n",
        "1. Sample from $\\epsilon\\sim\\mathcal{N}(O, \\mathbb{1})$\n",
        "2. $z = \\mu + \\sigma \\odot \\epsilon$\n",
        "\n",
        "This $z$ can then be passed on to the decoder. The backpropagation can now flow through the parameter vector, that is output by the encoder.\n",
        "\n",
        "This tricks allows us to construct the VAE loss function:\n",
        "\n",
        "$$\\mathcal{L}(x; \\theta, \\lambda) = \\mathbb{E}_{z\\sim q_\\lambda(z|x)}[\\log{p_\\theta(x|z)}] - d_{KL}(q_\\lambda(z|x), p_\\theta(z))$$\n",
        "\n",
        "By weighting the $d_{KL}$-term, we obtain the $\\beta$-VAE loss function:\n",
        "\n",
        "$$\\mathcal{L}(x; \\theta, \\lambda, \\beta) = \\mathbb{E}_{z\\sim q_\\lambda(z|x)}[\\log{p_\\theta(x|z)}] - \\beta*d_{KL}(q_\\lambda(z|x), p_\\theta(z))$$\n",
        "\n",
        "Here, we approximate $\\mathcal{L}(x; \\theta, \\lambda, \\beta)$ using a single-sample Monte Carlo Estimate:\n",
        "\n",
        "$$\\log{p_\\theta(x|z)} + \\beta*(\\log{p_\\theta(z)} - \\log{q_\\lambda(z|x)})$$\n"
      ],
      "metadata": {
        "id": "8EZ4sf5hG5Mt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Practical exercise today\n",
        "Today we will construct a variational autoencoder on the MNIST dataset, with the goal to generate new digit pictures. Each MNIST image is originally a vector of 784 integers, each of which is between 0-255 and represents the intensity of a pixel.\n",
        "\n",
        "Since we are dealing with a computer vision task, we will use a **convolutional** variational autoencoder (CVAE). The CVAE has the same bottleneck structure as a standard variational autoencoder, but replaces the dense layers with convolutional and tranposed convolutional layers. The former type used in the encoder for down-sampling, and the latter in the decoder for upsampling. As with any autoencoder, the goal of the CVAE is to learn the *identity function*: learn to reconstruct the input image after \"squeezing\" it through a low-dimensional latent representation, also called the *bottleneck*.\n",
        "\n",
        "Additionally, we will use a **variational** autoencoder for this task. This means we will use variational inference to find the optimal $\\theta$ and $\\lambda$ to parameterize, respectively, the decoder $p_\\theta(x|z)$ and the encoder $q_\\lambda(z|x)$, with $z$ the latent representation.\n",
        "\n",
        "In order for us to be able to use $p_\\theta(x|z)$, we need to first be able to choose a meaningfull $z$. Therefore, we will impose a Gaussian prior over $q_\\lambda(z|x)$. We'll see how this is done when we define the loss\n",
        "\n",
        "\n",
        "For today we will perform the following steps:\n",
        "* Load in and preprocess the dataset\n",
        "* Construct the CVAE class\n",
        "* Construct the leaning process of the CVAE\n",
        "* Run the CVAE model and generate new images"
      ],
      "metadata": {
        "id": "kui2LQciHmW2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing the data"
      ],
      "metadata": {
        "id": "zci_78osJL2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in the data\n",
        "(train_images, _), (test_images, _) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Normalize the pixel value range to [0.1] and threshold all pixels at 0.5\n",
        "def preprocess_images(images):\n",
        "  images = images.reshape((images.shape[0], 28, 28, 1)) / 255.\n",
        "  return np.where(images > .5, 1.0, 0.0).astype('float32')\n",
        "\n",
        "# Perform training and test splits\n",
        "train_images = preprocess_images(train_images)\n",
        "test_images = preprocess_images(test_images)\n",
        "\n",
        "# Set parameters\n",
        "train_size = 60000\n",
        "batch_size = 256\n",
        "test_size = 10000"
      ],
      "metadata": {
        "id": "sm2g08uUF3dS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the dataset and divide in batches\n",
        "train_dataset = (tf.data.Dataset.from_tensor_slices(train_images)\n",
        "                 .shuffle(train_size).batch(batch_size))\n",
        "test_dataset = (tf.data.Dataset.from_tensor_slices(test_images)\n",
        "                .shuffle(test_size).batch(batch_size))"
      ],
      "metadata": {
        "id": "w4b2KX9CGCHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the variational auttoencoder architecture"
      ],
      "metadata": {
        "id": "1Iu_W1-sJwTl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TASK 1**\n",
        "\n",
        "Implement the reparameterization trick in the `reparameterize` function below.\n",
        "\n",
        "**NOTE**:\n",
        "We use the log-normal distribution for numerical stability during training. This means:\n",
        "\n",
        "$$ \\sigma = \\sqrt{e^\\textrm{logvar}} $$"
      ],
      "metadata": {
        "id": "7qfgyaaJJ429"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CVAE(tf.keras.Model):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(CVAE, self).__init__()\n",
        "        \n",
        "        subsampled_size = 7\n",
        "        input_shape = (28, 28, 1)\n",
        "        \n",
        "        self.latent_dim = latent_dim\n",
        "        self.inference_net = tf.keras.Sequential([\n",
        "              tf.keras.layers.InputLayer(input_shape=input_shape),\n",
        "              tf.keras.layers.Conv2D( # This layer will downsample the image to half its width and height\n",
        "                  filters=32, kernel_size=3, strides=(2,2), activation='relu'),\n",
        "              tf.keras.layers.Conv2D( # This layer will downsample the image again to half its current width and height\n",
        "                  filters=64, kernel_size=3, strides=(2,2), activation='relu'),\n",
        "              tf.keras.layers.Flatten(),\n",
        "              # No activation\n",
        "              tf.keras.layers.Dense(latent_dim + latent_dim)])\n",
        "\n",
        "        self.generative_net = tf.keras.Sequential([\n",
        "              tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
        "              tf.keras.layers.Dense(units=subsampled_size*subsampled_size*32, activation=tf.nn.relu),\n",
        "              tf.keras.layers.Reshape(target_shape=(subsampled_size, subsampled_size, 32)),\n",
        "              tf.keras.layers.Conv2DTranspose( # This layer will upsample the image to twice its current width and height\n",
        "                  filters=64,\n",
        "                  kernel_size=3,\n",
        "                  strides=2,\n",
        "                  padding=\"SAME\",\n",
        "                  activation='relu'),\n",
        "              tf.keras.layers.Conv2DTranspose( # This layer will upsample the image again to twice its current width and height\n",
        "                  filters=32,\n",
        "                  kernel_size=3,\n",
        "                  strides=2,\n",
        "                  padding=\"SAME\",\n",
        "                  activation='relu'),\n",
        "              # No activation\n",
        "              tf.keras.layers.Conv2DTranspose(\n",
        "                  filters=input_shape[-1], kernel_size=3, strides=1, padding=\"SAME\")] )\n",
        "\n",
        "    @tf.function\n",
        "    def sample(self, eps=None):\n",
        "        if eps is None:\n",
        "            eps = tf.random.normal(shape=(100, self.latent_dim))\n",
        "        return self.decode(eps, apply_sigmoid=True)\n",
        "\n",
        "    def encode(self, x):\n",
        "        mean, logvar = tf.split(self.inference_net(x), num_or_size_splits=2, axis=1)\n",
        "        return mean, logvar\n",
        "\n",
        "    def reparameterize(self, mean, logvar):\n",
        "        # sample random noise\n",
        "        ...\n",
        "        #perform reparameterization\n",
        "        ...\n",
        "        return ...\n",
        "\n",
        "    def decode(self, z, apply_sigmoid=False):\n",
        "        logits = self.generative_net(z)\n",
        "        if apply_sigmoid:\n",
        "            probs = tf.sigmoid(logits)\n",
        "            return probs\n",
        "\n",
        "        return logits"
      ],
      "metadata": {
        "id": "KK6yEUlpJvgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TASK 2**\n",
        "\n",
        "Complete the missing parts in the function below to compute the loss.\n",
        "\n",
        "Remember Here, we approximate $\\mathcal{L}(x; \\theta, \\lambda, \\beta)$ using a single-sample Monte Carlo Estimate:\n",
        "\n",
        "$$\\log{p_\\theta(x|z)} + \\beta*(\\log{p_\\theta(z)} - \\log{q_\\lambda(z|x)})$$\n",
        "\n",
        "You could also analytically compute the KL term, but here we incorporate all three terms in the Monte Carlo estimator for simplicity"
      ],
      "metadata": {
        "id": "5Ox0HAXXJ76E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def log_normal_pdf(sample, mean, logvar, raxis=1): \n",
        "    log2pi = tf.math.log(2. * np.pi)\n",
        "    return tf.reduce_sum(-.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi), axis=raxis)"
      ],
      "metadata": {
        "id": "mnPsILDgKASt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_loss(model, x_true, beta=1):\n",
        "    mu, logvar = ... # parameters for the multivariate normal posterior\n",
        "    z = ...  # a sample from the posterior\n",
        "    x_recons_logits = ... # the reconstruction of the sample\n",
        "    \n",
        "    raw_cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=x_true,\n",
        "                        logits=x_recons_logits)\n",
        "    \n",
        "    neg_log_likelihood = tf.math.reduce_sum(raw_cross_entropy, axis=[1, 2, 3])\n",
        "    \n",
        "    logpz = ... # density of the prior evaluated at z_sample\n",
        "    logqz_x = ... # density of the latent posterior evaluated at z_sample\n",
        "    kl_divergence = logqz_x - logpz\n",
        "    \n",
        "    elbo = tf.math.reduce_mean(-beta * kl_divergence - neg_log_likelihood)\n",
        "    \n",
        "    return dict(\n",
        "        loss=-elbo, \n",
        "        reconstruction=-neg_log_likelihood, \n",
        "        kl=-kl_divergence\n",
        "    )"
      ],
      "metadata": {
        "id": "HE7lwb_kKFMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def compute_apply_gradients(model, x, optimizer, beta=1):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss = compute_loss(model, x, beta=beta)[\"loss\"]\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
      ],
      "metadata": {
        "id": "yz-BR40EKGBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TASK 3**\n",
        "\n",
        "Now it is time to train the $\\beta$-VAE.\n",
        "\n",
        "First, create a CVAE model with 2 latent dimensions. Then, create an Adam optimizer with a learning rate of 0.001. Finally, implement the iterative training procedure.\n",
        "\n",
        "Training pseudocode:\n",
        "```\n",
        "for every epoch\n",
        "    for every batch in train dataset\n",
        "        compute loss and apply gradients\n",
        "        \n",
        "    for every batch in test dataset\n",
        "        compute loss\n",
        "    \n",
        "    print test set loss\n",
        "```\n",
        "Make sure to use the `compute_apply_gradients` and `compute_loss` functions. Set $\\beta$ to 3.\n",
        "\n",
        "Complete the code to generate new images and compare the results of the first epoch to the last.\n",
        "\n"
      ],
      "metadata": {
        "id": "OFuVnK0AKPF-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "latent_dim = 2\n",
        "\n",
        "# define model\n",
        "model = ...\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = ..."
      ],
      "metadata": {
        "id": "cScI39DlKPNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick a sample of the test set for generating output images\n",
        "num_examples_to_generate = 16\n",
        "assert batch_size >= num_examples_to_generate\n",
        "for test_batch in test_dataset.take(1):\n",
        "  test_sample = test_batch[0:num_examples_to_generate, :, :, :]\n",
        "\n",
        "def generate_images(model, test_sample):\n",
        "  mean, logvar = model.encode(test_sample)\n",
        "  z = model.reparameterize(mean, logvar)\n",
        "  predictions = model.sample(z)\n",
        "  fig = plt.figure(figsize=(4, 4))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(4, 4, i + 1)\n",
        "      plt.imshow(predictions[i, :, :, 0], cmap='gray')\n",
        "      plt.axis('off')"
      ],
      "metadata": {
        "id": "MN8LFI3dPeRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "...  # generate images by the untrained model"
      ],
      "metadata": {
        "id": "TYTfKkCuPn2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: this can take quite a while, it takes appr. 94s for one epoch without gpu's.\n",
        "for epoch ...:\n",
        "  if epoch == 2:\n",
        "    ... # generated images by the model that is trained with one e^poch\n",
        "  start_time = time.time()\n",
        "  ... # loop over the train batches\n",
        "    ... # train the model\n",
        "  end_time = time.time()\n",
        "\n",
        "  ... # loop over the test batches\n",
        "    ... # test the model, return the losses\n",
        "  elbo = ... # extract the elbo loss\n",
        "  print('Epoch: {}, Test set ELBO: {}, time elapse for current epoch: {}'\n",
        "        .format(epoch, elbo, end_time - start_time))\n"
      ],
      "metadata": {
        "id": "PM7IucW1KXWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_images(model,test_sample ) # generate images by the fully trained model"
      ],
      "metadata": {
        "id": "wUP7BN17Ov9l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}